{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e284993f-b46d-4620-b5ec-c7a6571c340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5783845d-bbfd-457b-9fb6-5c6277f4019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('course_lead_scoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd8bd7d-cca3-448d-bc2a-3b5017a86128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1462, 9)\n",
      "\n",
      "First few rows:\n",
      "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
      "0      paid_ads         NaN                         1        79450.0   \n",
      "1  social_media      retail                         1        46992.0   \n",
      "2        events  healthcare                         5        78796.0   \n",
      "3      paid_ads      retail                         2        83843.0   \n",
      "4      referral   education                         3        85012.0   \n",
      "\n",
      "  employment_status       location  interaction_count  lead_score  converted  \n",
      "0        unemployed  south_america                  4        0.94          1  \n",
      "1          employed  south_america                  1        0.80          0  \n",
      "2        unemployed      australia                  3        0.69          1  \n",
      "3               NaN      australia                  1        0.87          0  \n",
      "4     self_employed         europe                  3        0.62          1  \n",
      "\n",
      "Column data types:\n",
      "lead_source                  object\n",
      "industry                     object\n",
      "number_of_courses_viewed      int64\n",
      "annual_income               float64\n",
      "employment_status            object\n",
      "location                     object\n",
      "interaction_count             int64\n",
      "lead_score                  float64\n",
      "converted                     int64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "lead_source                 128\n",
      "industry                    134\n",
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "employment_status           100\n",
      "location                     63\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumn data types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c79a5d9-4722-457b-877e-4f61458d1952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "# Handle missing values\n",
    "# Categorical features: replace with 'NA'\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ada88c-42a7-42ec-9d95-11c149be8372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after handling:\n",
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "converted                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Numerical features: replace with 0.0\n",
    "numerical_cols = df.select_dtypes(include=['number']).columns.drop('converted')\n",
    "for col in numerical_cols:\n",
    "    df[col] = df[col].fillna(0.0)\n",
    "\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7351fda-7709-458e-8372-3444a5a29f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "# First split: 60% train, 40% temp\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "\n",
    "# Second split: 20% validation, 20% test from the remaining\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bb8bd25-2507-412e-9b49-a4acc6ab8f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 293, 293)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check datasets sizes after splitting\n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7db61116-75b8-4eed-8fa6-6f0e57452dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset indexes\n",
    "df_train = df_train.reset_index(drop = True)\n",
    "df_test = df_test.reset_index(drop = True)\n",
    "df_val = df_val.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d65d0962-c8d3-443e-ac90-5b9e31491dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train size: 876 (59.9%)\n",
      "Validation size: 293 (20.0%)\n",
      "Test size: 293 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTrain size: {len(df_train)} ({len(df_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Validation size: {len(df_val)} ({len(df_val)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test size: {len(df_test)} ({len(df_test)/len(df)*100:.1f}%)\")\n",
    "\n",
    "y_train = df_train['converted'].values\n",
    "y_val = df_val['converted'].values\n",
    "y_test = df_test['converted'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e824166a-f527-4cb0-8122-236d50fe0eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_score: 0.6145\n",
      "number_of_courses_viewed: 0.7636\n",
      "interaction_count: 0.7383\n",
      "annual_income: 0.5520\n",
      "\n",
      "Highest AUC feature: number_of_courses_viewed with AUC = 0.7636\n"
     ]
    }
   ],
   "source": [
    "# Question 1: ROC AUC feature importance\n",
    "numerical_features = ['lead_score', 'number_of_courses_viewed', \n",
    "                      'interaction_count', 'annual_income']\n",
    "\n",
    "auc_scores = {}\n",
    "for feature in numerical_features:\n",
    "    score = df_train[feature].values\n",
    "    auc = roc_auc_score(y_train, score)\n",
    "    \n",
    "    # If AUC < 0.5, invert the variable\n",
    "    if auc < 0.5:\n",
    "        auc = roc_auc_score(y_train, -score)\n",
    "        print(f\"{feature}: {auc:.4f} (inverted)\")\n",
    "    else:\n",
    "        print(f\"{feature}: {auc:.4f}\")\n",
    "    \n",
    "    auc_scores[feature] = auc\n",
    "\n",
    "best_feature = max(auc_scores, key=auc_scores.get)\n",
    "print(f\"\\nHighest AUC feature: {best_feature} with AUC = {auc_scores[best_feature]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3b2a4ec-bc33-455b-9db6-56954a60ade2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape: (876, 31)\n",
      "Validation matrix shape: (293, 31)\n",
      "Number of features after encoding: 31\n",
      "\n",
      "Validation AUC: 0.817\n",
      "Rounded to 3 digits: 0.817\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Training the model\n",
    "\n",
    "# Prepare data for training\n",
    "def prepare_data(df):\n",
    "    # Drop the target column and convert to dictionary\n",
    "    df_features = df.drop('converted', axis=1)\n",
    "    df_dict = df_features.to_dict(orient='records')\n",
    "    return df_dict\n",
    "\n",
    "train_dict = prepare_data(df_train)\n",
    "val_dict = prepare_data(df_val)\n",
    "\n",
    "# One-hot encoding\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "print(f\"Training matrix shape: {X_train.shape}\")\n",
    "print(f\"Validation matrix shape: {X_val.shape}\")\n",
    "print(f\"Number of features after encoding: {len(dv.get_feature_names_out())}\")\n",
    "\n",
    "# Train logistic regression\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_pred_val = model.predict_proba(X_val)[:, 1]\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "print(f\"\\nValidation AUC: {auc_val:.3f}\")\n",
    "print(f\"Rounded to 3 digits: {round(auc_val, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0102710-2dfe-4a5a-abce-21604396fb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision and Recall intersect at threshold: 0.980\n",
      "At this threshold: Precision = 0.000, Recall = 0.000\n"
     ]
    }
   ],
   "source": [
    "# Question 3: Precision and Recall\n",
    "thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_binary = (y_pred_val >= threshold).astype(int)\n",
    "    \n",
    "    tp = ((y_pred_binary == 1) & (y_val == 1)).sum()\n",
    "    fp = ((y_pred_binary == 1) & (y_val == 0)).sum()\n",
    "    fn = ((y_pred_binary == 0) & (y_val == 1)).sum()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "# Find intersection point\n",
    "differences = [abs(p - r) for p, r in zip(precisions, recalls)]\n",
    "min_diff_idx = np.argmin(differences)\n",
    "intersection_threshold = thresholds[min_diff_idx]\n",
    "\n",
    "print(f\"Precision and Recall intersect at threshold: {intersection_threshold:.3f}\")\n",
    "print(f\"At this threshold: Precision = {precisions[min_diff_idx]:.3f}, Recall = {recalls[min_diff_idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94649dc5-e9cf-489d-a06c-da31cb50a9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum F1 score: 0.812\n",
      "At threshold: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Question 4: F1 Score\n",
    "f1_scores = []\n",
    "for p, r in zip(precisions, recalls):\n",
    "    if p + r > 0:\n",
    "        f1 = 2 * (p * r) / (p + r)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "max_f1_idx = np.argmax(f1_scores)\n",
    "max_f1_threshold = thresholds[max_f1_idx]\n",
    "max_f1_value = f1_scores[max_f1_idx]\n",
    "\n",
    "print(f\"Maximum F1 score: {max_f1_value:.3f}\")\n",
    "print(f\"At threshold: {max_f1_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf7f8a60-2432-4b7c-93a1-f80d077b383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: AUC = 0.8061\n",
      "Fold 2: AUC = 0.8714\n",
      "Fold 3: AUC = 0.7754\n",
      "Fold 4: AUC = 0.8018\n",
      "Fold 5: AUC = 0.8558\n",
      "\n",
      "Mean AUC: 0.8221\n",
      "Standard Deviation: 0.0358\n"
     ]
    }
   ],
   "source": [
    "# Question 5: 5-Fold CV\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "cv_scores = []\n",
    "\n",
    "full_train_dict = prepare_data(df_full_train)\n",
    "y_full_train = df_full_train['converted'].values\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(df_full_train), 1):\n",
    "    # Split data\n",
    "    df_train_fold = df_full_train.iloc[train_idx]\n",
    "    df_val_fold = df_full_train.iloc[val_idx]\n",
    "    \n",
    "    y_train_fold = df_train_fold['converted'].values\n",
    "    y_val_fold = df_val_fold['converted'].values\n",
    "    \n",
    "    # Prepare dictionaries\n",
    "    train_dict_fold = prepare_data(df_train_fold)\n",
    "    val_dict_fold = prepare_data(df_val_fold)\n",
    "    \n",
    "    # Transform\n",
    "    dv_fold = DictVectorizer(sparse=False)\n",
    "    X_train_fold = dv_fold.fit_transform(train_dict_fold)\n",
    "    X_val_fold = dv_fold.transform(val_dict_fold)\n",
    "    \n",
    "    # Train and evaluate\n",
    "    model_fold = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    model_fold.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    y_pred_fold = model_fold.predict_proba(X_val_fold)[:, 1]\n",
    "    auc_fold = roc_auc_score(y_val_fold, y_pred_fold)\n",
    "    cv_scores.append(auc_fold)\n",
    "    \n",
    "    print(f\"Fold {fold}: AUC = {auc_fold:.4f}\")\n",
    "\n",
    "mean_auc = np.mean(cv_scores)\n",
    "std_auc = np.std(cv_scores)\n",
    "\n",
    "print(f\"\\nMean AUC: {mean_auc:.4f}\")\n",
    "print(f\"Standard Deviation: {std_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e26fece-7907-4d3a-b334-b3db51239ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1e-06: mean = 0.560, std = 0.024\n",
      "C = 0.001: mean = 0.867, std = 0.029\n",
      "C = 1: mean = 0.822, std = 0.036\n",
      "\n",
      "Best C: 0.001\n",
      "With mean score: 0.867\n",
      "And std: 0.029\n"
     ]
    }
   ],
   "source": [
    "# Question 6: Hyperparameter Tuning\n",
    "C_values = [0.000001, 0.001, 1]\n",
    "results = []\n",
    "\n",
    "for C in C_values:\n",
    "    cv_scores_c = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(df_full_train), 1):\n",
    "        # Split data\n",
    "        df_train_fold = df_full_train.iloc[train_idx]\n",
    "        df_val_fold = df_full_train.iloc[val_idx]\n",
    "        \n",
    "        y_train_fold = df_train_fold['converted'].values\n",
    "        y_val_fold = df_val_fold['converted'].values\n",
    "        \n",
    "        # Prepare dictionaries\n",
    "        train_dict_fold = prepare_data(df_train_fold)\n",
    "        val_dict_fold = prepare_data(df_val_fold)\n",
    "        \n",
    "        # Transform\n",
    "        dv_fold = DictVectorizer(sparse=False)\n",
    "        X_train_fold = dv_fold.fit_transform(train_dict_fold)\n",
    "        X_val_fold = dv_fold.transform(val_dict_fold)\n",
    "        \n",
    "        # Train and evaluate\n",
    "        model_fold = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "        model_fold.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        y_pred_fold = model_fold.predict_proba(X_val_fold)[:, 1]\n",
    "        auc_fold = roc_auc_score(y_val_fold, y_pred_fold)\n",
    "        cv_scores_c.append(auc_fold)\n",
    "    \n",
    "    mean_score = np.mean(cv_scores_c)\n",
    "    std_score = np.std(cv_scores_c)\n",
    "    \n",
    "    results.append({\n",
    "        'C': C,\n",
    "        'mean': round(mean_score, 3),\n",
    "        'std': round(std_score, 3)\n",
    "    })\n",
    "    \n",
    "    print(f\"C = {C}: mean = {mean_score:.3f}, std = {std_score:.3f}\")\n",
    "\n",
    "# Find best C\n",
    "results_df = pd.DataFrame(results)\n",
    "max_mean = results_df['mean'].max()\n",
    "best_results = results_df[results_df['mean'] == max_mean]\n",
    "\n",
    "if len(best_results) > 1:\n",
    "    # If tie, select lowest std\n",
    "    min_std = best_results['std'].min()\n",
    "    best_results = best_results[best_results['std'] == min_std]\n",
    "    \n",
    "    if len(best_results) > 1:\n",
    "        # If still tie, select smallest C\n",
    "        best_c = best_results['C'].min()\n",
    "    else:\n",
    "        best_c = best_results['C'].values[0]\n",
    "else:\n",
    "    best_c = best_results['C'].values[0]\n",
    "\n",
    "print(f\"\\nBest C: {best_c}\")\n",
    "print(f\"With mean score: {results_df[results_df['C']==best_c]['mean'].values[0]}\")\n",
    "print(f\"And std: {results_df[results_df['C']==best_c]['std'].values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcce234-876a-4850-bf25-7ff1190b081f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MLZoomCamp_env)",
   "language": "python",
   "name": "mlzoomcamp_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
