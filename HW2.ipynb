{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0457b6c9-1abc-475a-a905-2801d22cb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423ae688-4f72-4eeb-9a0a-d55c41b763e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6b0ebd8-c5d6-40d5-9335-2b612ab9b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the required columns\n",
    "columns_to_use = [\n",
    "    'engine_displacement',\n",
    "    'horsepower',\n",
    "    'vehicle_weight',\n",
    "    'model_year',\n",
    "    'fuel_efficiency_mpg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576e2206-45dc-4b70-907a-709305eb1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df[columns_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b2f889-b219-438b-b87b-afab2df663d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "engine_displacement      0\n",
      "horsepower             708\n",
      "vehicle_weight           0\n",
      "model_year               0\n",
      "fuel_efficiency_mpg      0\n",
      "dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df_selected.isnull().sum())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a982653-14ed-4bf3-9d84-15efca2438a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values:\n",
      "engine_displacement    0.0\n",
      "horsepower             7.3\n",
      "vehicle_weight         0.0\n",
      "model_year             0.0\n",
      "fuel_efficiency_mpg    0.0\n",
      "dtype: float64\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show percentage of missing values\n",
    "print(\"Percentage of missing values:\")\n",
    "print((df_selected.isnull().sum() / len(df_selected) * 100).round(2))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9fced81-2f05-4bb5-84cf-f8aa65511748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   engine_displacement  horsepower  vehicle_weight  model_year  \\\n",
      "0                  170       159.0     3413.433759        2003   \n",
      "1                  130        97.0     3149.664934        2007   \n",
      "2                  170        78.0     3079.038997        2018   \n",
      "3                  220         NaN     2542.392402        2009   \n",
      "4                  210       140.0     3460.870990        2009   \n",
      "5                  190         NaN     2484.883986        2008   \n",
      "6                  240       127.0     3006.542287        2012   \n",
      "7                  150       239.0     3638.657780        2020   \n",
      "8                  250       174.0     2714.219310        2016   \n",
      "9                  150       123.0     3509.036569        2005   \n",
      "\n",
      "   fuel_efficiency_mpg  \n",
      "0            13.231729  \n",
      "1            13.688217  \n",
      "2            14.246341  \n",
      "3            16.912736  \n",
      "4            12.488369  \n",
      "5            17.271818  \n",
      "6            13.210412  \n",
      "7            12.848884  \n",
      "8            16.823554  \n",
      "9            12.298355  \n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df_selected.head(10))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0685f298-b8c9-4fbe-995c-b42eba0eaaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9704, 5)\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9704 entries, 0 to 9703\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   engine_displacement  9704 non-null   int64  \n",
      " 1   horsepower           8996 non-null   float64\n",
      " 2   vehicle_weight       9704 non-null   float64\n",
      " 3   model_year           9704 non-null   int64  \n",
      " 4   fuel_efficiency_mpg  9704 non-null   float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 379.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Basic info about the dataset\n",
    "print(\"Dataset shape:\", df_selected.shape)\n",
    "print(\"\\nDataset info:\")\n",
    "print(df_selected.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882f47c7-1c21-47ce-b5bc-49adb0fc39a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median (50% percentile) for 'horsepower': 149.0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate median for horsepower\n",
    "median_horsepower = df_selected['horsepower'].median()\n",
    "print(f\"Median (50% percentile) for 'horsepower': {median_horsepower}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ae79653-db5c-44e9-b845-eb3d245febce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle with seed 42\n",
    "np.random.seed(42)\n",
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split 60/20/20\n",
    "n = len(df_shuffled)\n",
    "n_train = int(0.6 * n)\n",
    "n_val = int(0.2 * n)\n",
    "n_test = n - n_train - n_val\n",
    "\n",
    "df_train = df_shuffled[:n_train]\n",
    "df_val = df_shuffled[n_train:n_train+n_val]\n",
    "df_test = df_shuffled[n_train+n_val:]\n",
    "\n",
    "# Separate target variable\n",
    "y_train = df_train['fuel_efficiency_mpg'].values\n",
    "y_val = df_val['fuel_efficiency_mpg'].values\n",
    "y_test = df_test['fuel_efficiency_mpg'].values\n",
    "\n",
    "# Drop target from features\n",
    "X_train = df_train.drop('fuel_efficiency_mpg', axis=1)\n",
    "X_val = df_val.drop('fuel_efficiency_mpg', axis=1)\n",
    "X_test = df_test.drop('fuel_efficiency_mpg', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f0527d6-fdae-4509-aed3-cc1282815307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with 0 fill: 0.51\n",
      "RMSE with mean fill: 0.39\n",
      "Better option: Fill with mean\n"
     ]
    }
   ],
   "source": [
    "def train_linear_regression(X, y):\n",
    "    \"\"\"Train linear regression without regularization\"\"\"\n",
    "    # Ensure X and y are numeric numpy arrays\n",
    "    X = np.array(X, dtype=float)\n",
    "    y = np.array(y, dtype=float)\n",
    "    \n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    XTX = X.T.dot(X)\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    return w_full[0], w_full[1:]\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSE\"\"\"\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "    se = (y_true - y_pred) ** 2\n",
    "    mse = se.mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "# First, identify and handle categorical columns\n",
    "# Keep only numeric columns for the regression\n",
    "numeric_columns = X_train.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Option 1: Fill with 0\n",
    "X_train_0 = X_train[numeric_columns].fillna(0).values.astype(float)\n",
    "X_val_0 = X_val[numeric_columns].fillna(0).values.astype(float)\n",
    "\n",
    "w0_opt1, w_opt1 = train_linear_regression(X_train_0, y_train)\n",
    "y_pred_opt1 = w0_opt1 + X_val_0.dot(w_opt1)\n",
    "rmse_opt1 = round(rmse(y_val, y_pred_opt1), 2)\n",
    "\n",
    "# Option 2: Fill with mean (computed from training data only)\n",
    "train_means = X_train[numeric_columns].mean()\n",
    "X_train_mean = X_train[numeric_columns].fillna(train_means).values.astype(float)\n",
    "X_val_mean = X_val[numeric_columns].fillna(train_means).values.astype(float)\n",
    "\n",
    "w0_opt2, w_opt2 = train_linear_regression(X_train_mean, y_train)\n",
    "y_pred_opt2 = w0_opt2 + X_val_mean.dot(w_opt2)\n",
    "rmse_opt2 = round(rmse(y_val, y_pred_opt2), 2)\n",
    "\n",
    "print(f\"RMSE with 0 fill: {rmse_opt1}\")\n",
    "print(f\"RMSE with mean fill: {rmse_opt2}\")\n",
    "\n",
    "if rmse_opt1 < rmse_opt2:\n",
    "    print(\"Better option: Fill with 0\")\n",
    "elif rmse_opt2 < rmse_opt1:\n",
    "    print(\"Better option: Fill with mean\")\n",
    "else:\n",
    "    print(\"Both options give the same RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28826263-898d-4301-9e19-d61e3bf7738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression_reg(X, y, r=0.0):\n",
    "    \"\"\"Train linear regression with L2 regularization (Ridge regression)\"\"\"\n",
    "    # Ensure X and y are numeric numpy arrays\n",
    "    X = np.array(X, dtype=float)\n",
    "    y = np.array(y, dtype=float)\n",
    "\n",
    "    # Add a column of ones for the bias term\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "\n",
    "    # Calculate X^T * X\n",
    "    XTX = X.T.dot(X)\n",
    "\n",
    "    # Add regularization term: r * I\n",
    "    # I is an identity matrix of size XTX.shape[0] x XTX.shape[1]\n",
    "    # np.eye(XTX.shape[0]) creates the identity matrix.\n",
    "    reg_term = r * np.eye(XTX.shape[0])\n",
    "    XTX_reg = XTX + reg_term\n",
    "\n",
    "    # Calculate the inverse: (X^T X + r * I)^-1\n",
    "    XTX_inv = np.linalg.inv(XTX_reg)\n",
    "\n",
    "    # Calculate the full weight vector: w = (X^T X + r * I)^-1 * X^T * y\n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "\n",
    "    # w_full[0] is the bias (w0), w_full[1:] are the other weights (w)\n",
    "    return w_full[0], w_full[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f44ac2bb-6fb7-4eff-b989-68134cbc5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSE\"\"\"\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "    se = (y_true - y_pred) ** 2\n",
    "    mse = se.mean()\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1086bbb3-0f0b-4650-be75-912a6143c1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Linear Regression with NA filled by 0:\n",
      "-------------------------------------------------\n",
      "r=0     | RMSE: 0.51\n",
      "r=0.01  | RMSE: 0.51\n",
      "r=0.1   | RMSE: 0.51\n",
      "r=1     | RMSE: 0.51\n",
      "r=5     | RMSE: 0.51\n",
      "r=10    | RMSE: 0.51\n",
      "r=100   | RMSE: 0.51\n",
      "-------------------------------------------------\n",
      "Best RMSE: 0.51\n",
      "Best r (smallest r for best RMSE): 0\n"
     ]
    }
   ],
   "source": [
    "r_values = [0, 0.01, 0.1, 1, 5, 10, 100]\n",
    "results = []\n",
    "best_rmse = float('inf')\n",
    "best_r = -1\n",
    "\n",
    "print(\"Regularized Linear Regression with NA filled by 0:\")\n",
    "print(\"-------------------------------------------------\")\n",
    "for r in r_values:\n",
    "    # 1. Train the model\n",
    "    w0, w = train_linear_regression_reg(X_train_0, y_train, r=r)\n",
    "\n",
    "    # 2. Predict on validation set\n",
    "    y_pred = w0 + X_val_0.dot(w)\n",
    "\n",
    "    # 3. Calculate RMSE\n",
    "    score = rmse(y_val, y_pred)\n",
    "    rounded_score = round(score, 2)\n",
    "\n",
    "    results.append((r, rounded_score))\n",
    "    print(f\"r={r:<5} | RMSE: {rounded_score}\")\n",
    "\n",
    "    # 4. Check for best r (smallest r for the best RMSE)\n",
    "    if rounded_score < best_rmse:\n",
    "        best_rmse = rounded_score\n",
    "        best_r = r\n",
    "    elif rounded_score == best_rmse:\n",
    "        # If RMSE is equal, keep the current best_r since r is iterated from smallest to largest\n",
    "        pass\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------------\")\n",
    "print(f\"Best RMSE: {best_rmse}\")\n",
    "print(f\"Best r (smallest r for best RMSE): {best_r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feafaf3c-331b-484c-9db0-80c40e438175",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "rmse_scores = []\n",
    "# ... (N_train and N_val calculation) ...\n",
    "\n",
    "for seed in seeds:\n",
    "    # 1. Shuffle and split using the current seed\n",
    "    np.random.seed(seed)\n",
    "    df_shuffled = df_selected.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    df_train = df_shuffled[:n_train]\n",
    "    df_val = df_shuffled[n_train:n_train+n_val]\n",
    "\n",
    "    y_train = df_train['fuel_efficiency_mpg'].values\n",
    "    y_val = df_val['fuel_efficiency_mpg'].values\n",
    "\n",
    "    # 2. Impute NA with 0\n",
    "    feature_cols = ['engine_displacement', 'horsepower', 'vehicle_weight', 'model_year']\n",
    "    X_train_0 = df_train[feature_cols].fillna(0).values.astype(float)\n",
    "    X_val_0 = df_val[feature_cols].fillna(0).values.astype(float)\n",
    "\n",
    "    # 3. Train and 4. Evaluate\n",
    "    w0, w = train_linear_regression(X_train_0, y_train)\n",
    "    y_pred = w0 + X_val_0.dot(w)\n",
    "    score = rmse(y_val, y_pred)\n",
    "    rmse_scores.append(score)\n",
    "\n",
    "# 5. Calculate standard deviation\n",
    "std_rmse = np.std(rmse_scores)\n",
    "rounded_std = round(std_rmse, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20a79031-1c9c-450a-9cfd-bdb7b39527c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation (rounded to 3 decimal places): 0.007\n"
     ]
    }
   ],
   "source": [
    "print(f\"Standard deviation (rounded to 3 decimal places): {rounded_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0706e3ff-401c-4f50-96bc-469e02bec3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test dataset (r=0.001, seed=9): 0.167\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Function Definitions ---\n",
    "def train_linear_regression_reg(X, y, r=0.0):\n",
    "    \"\"\"Train linear regression with L2 regularization (Ridge regression)\"\"\"\n",
    "    # Add a column of ones for the bias term\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "\n",
    "    # Calculate X^T * X\n",
    "    XTX = X.T.dot(X)\n",
    "\n",
    "    # Add regularization term: r * I\n",
    "    reg_term = r * np.eye(XTX.shape[0])\n",
    "    XTX_reg = XTX + reg_term\n",
    "\n",
    "    # Calculate the inverse: (X^T X + r * I)^-1\n",
    "    XTX_inv = np.linalg.inv(XTX_reg)\n",
    "\n",
    "    # Calculate the full weight vector: w = (X^T X + r * I)^-1 * X^T * y\n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "\n",
    "    # w_full[0] is the bias (w0), w_full[1:] are the other weights (w)\n",
    "    return w_full[0], w_full[1:]\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Calculates the Root Mean Squared Error (RMSE).\"\"\"\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "    se = (y_true - y_pred) ** 2\n",
    "    mse = se.mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "# --- Main Calculation ---\n",
    "# 1. Load the data\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# 2. Data Preparation and Feature Selection\n",
    "# Calculate the log-transformed combined MPG (target variable)\n",
    "df['combined_mpg'] = (df['city mpg'] + df['highway MPG']) / 2\n",
    "y = np.log1p(df['combined_mpg'])\n",
    "feature_cols = ['Engine HP', 'Engine Cylinders', 'Popularity', 'Year']\n",
    "X = df[feature_cols]\n",
    "\n",
    "# 3. Split the data (60%/20%/20%) using seed 9\n",
    "seed = 9\n",
    "n = len(df)\n",
    "n_train = int(0.6 * n)\n",
    "n_val = int(0.2 * n)\n",
    "n_test = n - n_train - n_val\n",
    "\n",
    "idx = np.arange(n)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Apply shuffled index to X and y\n",
    "X_shuffled = X.iloc[idx].reset_index(drop=True)\n",
    "y_shuffled = y.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "# Split datasets\n",
    "X_train = X_shuffled[:n_train]\n",
    "X_val = X_shuffled[n_train:n_train+n_val]\n",
    "X_test = X_shuffled[n_train+n_val:]\n",
    "\n",
    "y_train = y_shuffled[:n_train].values\n",
    "y_val = y_shuffled[n_train:n_train+n_val].values\n",
    "y_test = y_shuffled[n_train+n_val:].values\n",
    "\n",
    "# 4. Combine train and validation datasets\n",
    "X_train_val = pd.concat([X_train, X_val])\n",
    "y_train_val = np.concatenate([y_train, y_val])\n",
    "\n",
    "# 5. Prepare features: Fill NA with 0\n",
    "# Prepare X_train_val\n",
    "X_train_val_0 = X_train_val.fillna(0).values.astype(float)\n",
    "# Prepare X_test\n",
    "X_test_0 = X_test.fillna(0).values.astype(float)\n",
    "\n",
    "# 6. Train the model with r=0.001\n",
    "r = 0.001\n",
    "w0, w = train_linear_regression_reg(X_train_val_0, y_train_val, r=r)\n",
    "\n",
    "# 7. Evaluate on the test dataset\n",
    "y_pred_test = w0 + X_test_0.dot(w)\n",
    "rmse_test = rmse(y_test, y_pred_test)\n",
    "\n",
    "# 8. Output\n",
    "rounded_rmse = round(rmse_test, 3)\n",
    "\n",
    "print(f\"RMSE on the test dataset (r={r}, seed={seed}): {rounded_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe5603-cbd2-47ee-9ac5-2f7700cf979b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3051c-f1e4-4e06-a34e-7f9860733b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44492c59-7f44-4a32-b2f9-65cab041fd28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
